
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Gaussian Processes 3: Sparse GPs with inducing points &#8212; Research Notes</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/gaussian_processes/pseudo_data';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="prev" title="Gaussian Processes 2: Gaussian process regression" href="gp_regression.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Research Notes - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Research Notes - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Machine Learning Notes
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="overview.html">Gaussian Processes</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="preliminaries.html">Gaussian Processes 1: Preliminaries</a></li>
<li class="toctree-l2"><a class="reference internal" href="gp_regression.html">Gaussian Processes 2: Gaussian process regression</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Gaussian Processes 3: Sparse GPs with inducing points</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/ethanweinberger/Research_Notes" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/ethanweinberger/Research_Notes/issues/new?title=Issue%20on%20page%20%2Fcontent/gaussian_processes/pseudo_data.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/content/gaussian_processes/pseudo_data.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Gaussian Processes 3: Sparse GPs with inducing points</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="gaussian-processes-3-sparse-gps-with-inducing-points">
<h1>Gaussian Processes 3: Sparse GPs with inducing points<a class="headerlink" href="#gaussian-processes-3-sparse-gps-with-inducing-points" title="Link to this heading">#</a></h1>
<p>In the previous section we discussed how to perform Gaussian process regression to estimate the
values of a function <span class="math notranslate nohighlight">\(f\)</span>. Our solution relied on the convenient properties of the multivariate
normal distribution, which allowed us to compute posterior distributions of unknown function outputs
in closed form.</p>
<p>Unfortunately, while it’s straightforward to write down the equations for the posterior distribution,
actually <em>computing</em> it is non-trivial. Specifically, the posterior distribution requires inverting
the covariance matrix <span class="math notranslate nohighlight">\(K(X, X)\)</span>, which requires <span class="math notranslate nohighlight">\(\mathcal{O}(N^3)\)</span> operations; thus as the size of our training
data increases, this operation quickly becomes infeasible.</p>
<p>To work around this issue, a number of works have proposed so-called <em>sparse</em> Gaussian process methods that take varying
approaches to approximate the information contained in the full covariance matrix. In this section we’ll review one popular
sparse GP method, known as the <em>inducing point</em> method.</p>
<hr class="docutils" />
<p>When placing a GP prior on a function, we implicitly assert the existence of some redundancy and/or correlation in the relationship between the function’s inputs and outputs. For example, the RBF kernel</p>
<div class="math notranslate nohighlight">
\[k(\mathbf{x}, \mathbf{x}') = \exp\left(-\frac{||\mathbf{x} - \mathbf{x}'||^2}{2\sigma^2}\right)\]</div>
<p>enforces that function outputs corresponding to similar inputs should observe a high degree of correlation. For large training datasets, we can then imagine that it might be possible to remove some points from the dataset, thus reducing our computational burden, without having a great impact on our predictions.</p>
<p>Taking this idea one step further, we can imagine that it might be possible to design some ideal “pseudo-dataset” <span class="math notranslate nohighlight">\(\bar{\mathcal{D}} = \{\mathbf{x}_m, \bar{f}_m\}_{m=1}^{M}\)</span> with <span class="math notranslate nohighlight">\(M &lt;&lt; N\)</span> that captures a similar amount of information as the full dataset. Note that here for our pseudo-dataset we have intentially used <span class="math notranslate nohighlight">\(\bar{f}\)</span> to describe our output values rather than <span class="math notranslate nohighlight">\(\bar{y}\)</span>, as it doesn’t make much sense to add noise to output function values that we’re choosing ourselves.</p>
<hr class="docutils" />
<p>Assuming that our pseudo-dataset can take the place of the full dataset, an output <span class="math notranslate nohighlight">\(y\)</span> has the likelihood</p>
<div class="math notranslate nohighlight">
\[ p(y \mid \mathbf{x}, \bar{X}, \bar{\mathbf{f}}) = \mathcal{N}(k_{\mathbf{x}}^{T}K_{\bar{X}\bar{X}}^{-1}\bar{\mathbf{f}}, K_{\mathbf{x}\mathbf{x}} - k_{\mathbf{x}}^{T}K_{\bar{X}\bar{X}}^{-1}k_{\mathbf{x}} + \sigma^2),\]</div>
<p>where <span class="math notranslate nohighlight">\(k_{\mathbf{x}} \in \mathbb{R}^{M}\)</span> is shorthand for a vector with entries <span class="math notranslate nohighlight">\(k(\mathbf{x}, \mathbf{x}_m)\)</span>. Assuming that our full set of test data <span class="math notranslate nohighlight">\(\mathbf{y} = \{y\}_{n=1}^{N}\)</span>, are i.i.d., <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> then has the following likelihood:</p>
<div class="math notranslate nohighlight" id="equation-likelihood">
<span class="eqno">(1)<a class="headerlink" href="#equation-likelihood" title="Link to this equation">#</a></span>\[p(\mathbf{y} \mid X, \bar{X}, \bar{\mathbf{f}}) = \prod_{n=1}^{N} p(y_n \mid \mathbf{x}_n, \bar{X}, \bar{\mathbf{f}}) = \mathcal{N}(\mathbf{y} \mid K_{NM}K_{M}^{-1}\bar{\mathbf{f}}, \mathbf{\Lambda} + \sigma^2I),\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{\Lambda} = \text{diag}(\mathbf{\lambda})\)</span>, and <span class="math notranslate nohighlight">\(\lambda_n = K_{\mathbf{x}_n\mathbf{x}_n} - k_{\mathbf{x}_n}^{T}K_{M}^{-1}k_{\mathbf{x}_n}\)</span>. With our model specified, we must now resolve two issues. First, we neeed to specify some criterion for choosing a “good” pseudo-dataset.</p>
<p>One way to do so would be to optimize <span class="math notranslate nohighlight">\(\bar{\mathbf{f}}\)</span> and <span class="math notranslate nohighlight">\(\bar{X}\)</span> to maximize the above likelihood. However, by treating <span class="math notranslate nohighlight">\(\bar{\mathbf{f}}\)</span> with some uncertainty we can actually make our lives easier and avoid the need to optimize this quantity altogether. To ensure that the pseudo data outputs model the true dataset well, it’s reasonable to assume that that they follow the same prior as true data points, i.e.,</p>
<div class="math notranslate nohighlight" id="equation-pseudo-prior">
<span class="eqno">(2)<a class="headerlink" href="#equation-pseudo-prior" title="Link to this equation">#</a></span>\[p(\bar{\mathbf{f}} \mid \bar{X}) = \mathcal{N}(0, K_{\bar{X}\bar{X}}).\]</div>
<p>With this assumption, we can then marginalize out <span class="math notranslate nohighlight">\(\bar{\mathbf{f}}\)</span> from Equation <a class="reference internal" href="#equation-likelihood">(1)</a>. I.e., we compute</p>
<div class="math notranslate nohighlight">
\[ p(\mathbf{y} \mid X, \bar{X}) = \int p(\mathbf{y} \mid X, \bar{X}, \bar{\mathbf{f}})p(\bar{\mathbf{f}} \mid \bar{X})d\bar{\mathbf{f}}, \]</div>
<p>From the properties of Gaussians this integral has a closed form and results in</p>
<div class="math notranslate nohighlight">
\[ p(\mathbf{y} \mid X, \bar{X}) = \mathcal{N}(\mathbf{y} \mid 0, K_{NM}K_{M}^{-1}K_{MN} + \mathbf{\Lambda} + \sigma^2I).\]</div>
<p>And so we can find a good set of pseudo-inputs <span class="math notranslate nohighlight">\(\bar{X}\)</span> by maximizing the above expression for the marginal likelihood. Next, we need a way to make predictions on the distribution of unseen points given our observed data. In other words, we need a method for computing <span class="math notranslate nohighlight">\(p(y_* \mid \mathbf{x}_*, X, \bar{X}, \mathbf{y})\)</span>. Of particular note, we can’t simply reuse our result from Equation <a class="reference internal" href="#equation-likelihood">(1)</a>, as that expression depends on the pseudo-outputs <span class="math notranslate nohighlight">\(\bar{\mathbf{f}}\)</span>, which we chose not to learn. Thus, we must instead compute</p>
<div class="math notranslate nohighlight" id="equation-predictive-dist">
<span class="eqno">(3)<a class="headerlink" href="#equation-predictive-dist" title="Link to this equation">#</a></span>\[p(y_* \mid \mathbf{x}_*, X, \bar{X}, \mathbf{y})  = \int p(y_* \mid \mathbf{x}_*, X, \bar{X}, \mathbf{y}, \bar{\mathbf{f}})p(\bar{\mathbf{f}} \mid X, \bar{X}, \mathbf{y})d\mathbf{\bar{f}}.\]</div>
<p>The first term in this integral is essentially Equation <a class="reference internal" href="#equation-likelihood">(1)</a>, and thus is straightforward to compute. To obtain the second term we can apply Bayes rule with Equations <a class="reference internal" href="#equation-likelihood">(1)</a> and <a class="reference internal" href="#equation-pseudo-prior">(2)</a> to obtain:</p>
<div class="math notranslate nohighlight">
\[ p(\bar{\mathbf{f}} \mid X, \bar{X}, \mathbf{y}) = \mathcal{N}(\bar{\mathbf{f}} \mid K_{\bar{X}\bar{X}}Q^{-1}K_{\bar{X}X}(\mathbf{\Lambda} + \sigma^2I)\mathbf{y}, K_{\bar{X}\bar{X}}Q^{-1}K_{\bar{X}\bar{X}}),\]</div>
<p>where <span class="math notranslate nohighlight">\(Q = K_{\bar{X}\bar{X}} + K_{\bar{X}X}(\mathbf{\Lambda} + \sigma^2I)K_{X\bar{X}}\)</span>.</p>
<p>Plugging this expression into Equation <a class="reference internal" href="#equation-predictive-dist">(3)</a> we have (after some tedious computations leveraging the properties of Gaussians):</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
p(y_* \mid \mathbf{x}_*, X, \bar{X}, \mathbf{y}) &amp;= \mathcal{N}(y_* \mid \mu_*, \sigma^2_*), \\
\mu_* &amp;= k_{\mathbf{x}_*}^{T}Q^{-1}K_{\bar{X}X}(\mathbf{\Lambda} + \sigma^2I)^{-1}\mathbf{y}, \\
\sigma_*^2 &amp;= K_{\mathbf{x}_*\mathbf{x}_*} - k_{\mathbf{x}_*}^{T}(K_{\bar{X}\bar{X}}^{-1} - Q^{-1})k_{\mathbf{x}_*} + \sigma^2
\end{align}
\end{split}\]</div>
<p>Before moving on, let’s briefly consider the cost of computing the above distribution. Calculating <span class="math notranslate nohighlight">\(Q\)</span> requires multiplying a matrix with dimensions <span class="math notranslate nohighlight">\(M \times N\)</span> and a matrix with dimensions <span class="math notranslate nohighlight">\(N \times M\)</span>, and thus this step is of order <span class="math notranslate nohighlight">\(\mathcal{O}(M^2N)\)</span>. As they are both <span class="math notranslate nohighlight">\(M \times M\)</span> matrices, computing the inverses of <span class="math notranslate nohighlight">\(Q\)</span> and <span class="math notranslate nohighlight">\(K_{\bar{X}\bar{X}}\)</span> requires <span class="math notranslate nohighlight">\(\mathcal{O}(M^3)\)</span> steps. Notably, the remaining inverse computation for <span class="math notranslate nohighlight">\(\mathbf{\Lambda} + \sigma^2I\)</span> is trivial, as this matrix is diagonal. As we take <span class="math notranslate nohighlight">\(M &lt;&lt; N\)</span>, our prediction step is thus dominated by the <span class="math notranslate nohighlight">\(\mathcal{O}(M^2N)\)</span> term, which is indeed a major improvement on the  <span class="math notranslate nohighlight">\(\mathcal{O}(N^3)\)</span> computations required for exact GP regression.</p>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/gaussian_processes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="gp_regression.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Gaussian Processes 2: Gaussian process regression</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Ethan Weinberger
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>